{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas  as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, confusion_matrix, classification_report\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from joblib import load, dump\n",
    "from text_preproc_pipeline import preproc\n",
    "from env import *\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vects(df):\n",
    "    title_vec_model_final = load(r'vectoriser_models\\title_tfidf_cat5_v4_1.pkl')\n",
    "    desc_vec_model_final = load(r'vectoriser_models\\desc_tfidf_cat5_v4_1.pkl')\n",
    "    subcat_vec_model_final = load(r'vectoriser_models\\subcat_tfidf_cat5_v4_1.pkl')\n",
    "    pl_vec_model_final = load(r'vectoriser_models\\pl_tfidf_cat5_v4_1.pkl')\n",
    "\n",
    "    title_mat = title_vec_model_final.transform(df['title_proc'].fillna(''))\n",
    "    desc_mat = desc_vec_model_final.transform(df['desc_proc'].fillna(''))\n",
    "    subcat_mat = subcat_vec_model_final.transform(df['subcat_proc'].fillna(''))\n",
    "    pl_mat = pl_vec_model_final.transform(df['pl_proc'].fillna(''))\n",
    "\n",
    "    X_mat = hstack((title_mat, desc_mat, subcat_mat, pl_mat))\n",
    "    return X_mat\n",
    "\n",
    "### tokenising the independent variables\n",
    "def preproc2(df_proc, isbase=False):\n",
    "    df_proc['title_proc'] = df_proc['title'].apply(lambda x: preproc(x))\n",
    "    df_proc['desc_proc'] = df_proc['description'].apply(lambda x: preproc(x))\n",
    "    df_proc['subcat_proc'] = df_proc['shopify_subcategory'].apply(lambda x: preproc(x))\n",
    "    if isbase == True:\n",
    "        df_proc['pl_proc'] = df_proc['page_link'].str.split('/products/',expand=True)[1].apply(lambda x: preproc(x))\n",
    "    else:\n",
    "        df_proc['pl_proc'] = df_proc['page_link'].apply(lambda x: preproc(x))\n",
    "\n",
    "    df2 = df_proc[['title_proc','subcat_proc','desc_proc', 'pl_proc']]\n",
    "\n",
    "    return vects(df2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(models, df_main, baseline_df):\n",
    "\n",
    "    df_list = []\n",
    "    X_mat = preproc2(df_main)\n",
    "    y = df_main['category5_token']\n",
    "    X_base_mat = preproc2(baseline_df, isbase=True)\n",
    "    y_base = baseline_df['cat5_tokens']\n",
    "    y_bin = LabelBinarizer().fit_transform(y)\n",
    "    \n",
    "\n",
    "    for name, model in models:\n",
    "        start = time.time()\n",
    "        clf = model.fit(X_mat, y)\n",
    "        stop = time.time()\n",
    "        y_hat = clf.predict(X_mat)\n",
    "        acc = accuracy_score(y, y_hat)\n",
    "        y_hat_base = clf.predict(X_base_mat)\n",
    "        base_acc = accuracy_score(y_base, y_hat_base)\n",
    "        roc_sc = roc_auc_score(y_bin, clf.predict_proba(X_mat), multi_class=\"ovr\")\n",
    "\n",
    "        score_df = pd.DataFrame({\n",
    "            'model_name' : [name],\n",
    "            'Accuracy' : [acc],\n",
    "            'Baseline_accuracy' : [base_acc],\n",
    "            'roc_auc_score_ovr' : [roc_sc],\n",
    "            'training_time_min' : [(stop-start)/60]\n",
    "        })\n",
    "        df_list.append(score_df)        \n",
    "        dump(clf, f'classification_models/{name}_model.pkl')\n",
    "\n",
    "    final_scores = pd.concat(df_list)\n",
    "    final_scores.to_csv('final_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93638, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('new_train_set_93k.csv')\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(823, 13)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = pd.read_csv('baseline_14112022.csv').rename(columns={'id':'_id', 'store_id':'_store_id', 'handle':'page_link', 'body_html':'description', 'product_type' :'shopify_subcategory'})\n",
    "base_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:15:32] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "models = [('naive_bayes', MultinomialNB()), \n",
    "          ('decision_tree', DecisionTreeClassifier()),\n",
    "          ('random_forest', RandomForestClassifier()), \n",
    "          ('xgboost', XGBClassifier()),\n",
    "          ('lightgbm', LGBMClassifier())\n",
    "        ]\n",
    "\n",
    "train_models(models, df_train, base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Baseline_accuracy</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.919819</td>\n",
       "      <td>0.741191</td>\n",
       "      <td>0.048277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.999178</td>\n",
       "      <td>0.918591</td>\n",
       "      <td>11.727274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.999178</td>\n",
       "      <td>0.972053</td>\n",
       "      <td>7.843192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.999028</td>\n",
       "      <td>0.922236</td>\n",
       "      <td>41.518883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.013563</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>56.002119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  Accuracy  Baseline_accuracy  training_time\n",
       "0    naive_bayes  0.919819           0.741191       0.048277\n",
       "1  decision_tree  0.999178           0.918591      11.727274\n",
       "2  random_forest  0.999178           0.972053       7.843192\n",
       "3        xgboost  0.999028           0.922236      41.518883\n",
       "4       lightgbm  0.013563           0.001215      56.002119"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.read_csv('final_scores.csv')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [110], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m lb \u001b[39m=\u001b[39m LabelBinarizer()\n\u001b[0;32m     10\u001b[0m roc_list\u001b[39m=\u001b[39m []\n\u001b[1;32m---> 11\u001b[0m X_base_mat \u001b[39m=\u001b[39m preproc2(df_train)\n\u001b[0;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m pkl_file \u001b[39min\u001b[39;00m pkl_files:\n\u001b[0;32m     15\u001b[0m     nb \u001b[39m=\u001b[39m load(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclassification_models/\u001b[39m\u001b[39m{\u001b[39;00mpkl_file\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [2], line 19\u001b[0m, in \u001b[0;36mpreproc2\u001b[1;34m(df_proc, isbase)\u001b[0m\n\u001b[0;32m     17\u001b[0m df_proc[\u001b[39m'\u001b[39m\u001b[39mtitle_proc\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_proc[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: preproc(x))\n\u001b[0;32m     18\u001b[0m df_proc[\u001b[39m'\u001b[39m\u001b[39mdesc_proc\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_proc[\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: preproc(x))\n\u001b[1;32m---> 19\u001b[0m df_proc[\u001b[39m'\u001b[39m\u001b[39msubcat_proc\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_proc[\u001b[39m'\u001b[39;49m\u001b[39mshopify_subcategory\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: preproc(x))\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m isbase \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m     df_proc[\u001b[39m'\u001b[39m\u001b[39mpl_proc\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_proc[\u001b[39m'\u001b[39m\u001b[39mpage_link\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/products/\u001b[39m\u001b[39m'\u001b[39m,expand\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: preproc(x))\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1088\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1085\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1143\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   1138\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1143\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1144\u001b[0m             values,\n\u001b[0;32m   1145\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1146\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1147\u001b[0m         )\n\u001b[0;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1150\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn [2], line 19\u001b[0m, in \u001b[0;36mpreproc2.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     17\u001b[0m df_proc[\u001b[39m'\u001b[39m\u001b[39mtitle_proc\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_proc[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: preproc(x))\n\u001b[0;32m     18\u001b[0m df_proc[\u001b[39m'\u001b[39m\u001b[39mdesc_proc\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_proc[\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: preproc(x))\n\u001b[1;32m---> 19\u001b[0m df_proc[\u001b[39m'\u001b[39m\u001b[39msubcat_proc\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_proc[\u001b[39m'\u001b[39m\u001b[39mshopify_subcategory\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: preproc(x))\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m isbase \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m     df_proc[\u001b[39m'\u001b[39m\u001b[39mpl_proc\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_proc[\u001b[39m'\u001b[39m\u001b[39mpage_link\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/products/\u001b[39m\u001b[39m'\u001b[39m,expand\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: preproc(x))\n",
      "File \u001b[1;32mc:\\DTown_internship\\DataScience\\new_classifiers\\text_preproc_pipeline.py:32\u001b[0m, in \u001b[0;36mpreproc\u001b[1;34m(series)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreproc\u001b[39m(series):\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m lemmatize(to_tokens(remove_punct(remove_numbers(to_lower(series)))))\n",
      "File \u001b[1;32mc:\\DTown_internship\\DataScience\\new_classifiers\\text_preproc_pipeline.py:24\u001b[0m, in \u001b[0;36mto_tokens\u001b[1;34m(series)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_tokens\u001b[39m(series):\n\u001b[1;32m---> 24\u001b[0m     stop \u001b[39m=\u001b[39m stopwords\u001b[39m.\u001b[39;49mwords(\u001b[39m'\u001b[39;49m\u001b[39menglish\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([item \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m word_tokenize(series) \u001b[39mif\u001b[39;00m item \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop])\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwords\u001b[39m(\u001b[39mself\u001b[39m, fileids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ignore_lines_startswith\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m line_tokenize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw(fileids))\n\u001b[0;32m     22\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m contents \u001b[39m=\u001b[39m []\n\u001b[0;32m    217\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fileids:\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopen(f) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    219\u001b[0m         contents\u001b[39m.\u001b[39mappend(fp\u001b[39m.\u001b[39mread())\n\u001b[0;32m    220\u001b[0m \u001b[39mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[0m, in \u001b[0;36mCorpusReader.open\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[39mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m encoding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding(file)\n\u001b[1;32m--> 231\u001b[0m stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_root\u001b[39m.\u001b[39;49mjoin(file)\u001b[39m.\u001b[39;49mopen(encoding)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\nltk\\data.py:326\u001b[0m, in \u001b[0;36mFileSystemPathPointer.open\u001b[1;34m(self, encoding)\u001b[0m\n\u001b[0;32m    324\u001b[0m stream \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 326\u001b[0m     stream \u001b[39m=\u001b[39m SeekableUnicodeStreamReader(stream, encoding)\n\u001b[0;32m    327\u001b[0m \u001b[39mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\nltk\\compat.py:41\u001b[0m, in \u001b[0;36mpy3_data.<locals>._decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decorator\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m     args \u001b[39m=\u001b[39m (args[\u001b[39m0\u001b[39m], add_py3_data(args[\u001b[39m1\u001b[39m])) \u001b[39m+\u001b[39m args[\u001b[39m2\u001b[39m:]\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m init_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\nltk\\data.py:991\u001b[0m, in \u001b[0;36mSeekableUnicodeStreamReader.__init__\u001b[1;34m(self, stream, encoding, errors)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[39m@py3_data\u001b[39m\n\u001b[0;32m    989\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, stream, encoding, errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    990\u001b[0m     \u001b[39m# Rewind the stream to its beginning.\u001b[39;00m\n\u001b[1;32m--> 991\u001b[0m     stream\u001b[39m.\u001b[39;49mseek(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    993\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m stream\n\u001b[0;32m    994\u001b[0m     \u001b[39m\"\"\"The underlying stream.\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pkl_files = ['naive_bayes_model.pkl',\n",
    "             'decision_tree_model.pkl',\n",
    "             'random_forest_model.pkl',\n",
    "             'xgboost_model.pkl',\n",
    "             'lightgbm_model.pkl'\n",
    "            ]\n",
    "\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "roc_list= []\n",
    "X_mat = preproc2(df_train)\n",
    "y = df_train['category5_token']\n",
    "y_bin = lb.fit_transform(y)\n",
    "\n",
    "\n",
    "for pkl_file in pkl_files:\n",
    "    model = load(f'classification_models/{pkl_file}')\n",
    "    y_proba = model.predict_proba(X_mat)\n",
    "    roc_sc = roc_auc_score(y_bin, y_proba, multi_class='ovr')\n",
    "    roc_list.append(roc_sc)\n",
    "\n",
    "score_df = pd.read_csv('final_scores.csv')\n",
    "score_df['roc_auc_score_ovr'] = roc_list\n",
    "score_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8f46350a8bd583910db51a1d64064108b958bcbad0d091bd79d552637a4ab30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

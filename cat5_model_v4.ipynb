{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "import pandas  as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from text_preproc_pipeline import preproc\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from joblib import load\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# from env import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90292, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train = pd.read_csv(\"cat5_training_set_final_08112022.csv\")\n",
    "df_train = pd.read_json(\"cat5_training_set_final_08112022.json\", orient='split')\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_proc(df, fn, n_cores=5):\n",
    "    if cpu_count() < n_cores:\n",
    "        raise ValueError(\"The number of CPU's specified exceed the amount available\")\n",
    "\n",
    "    df_list = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    res = pool.map(fn, df_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tokenising the independent variables\n",
    "\n",
    "df_train['title_proc'] = df_train['title'].apply(lambda x: preproc(x))\n",
    "df_train['desc_proc'] = df_train['description'].apply(lambda x: preproc(x))\n",
    "df_train['subcat_proc'] = df_train['shopify_subcategory'].apply(lambda x: preproc(x))\n",
    "df_train['pl_proc'] = df_train['page_link'].apply(lambda x: preproc(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1715584</th>\n",
       "      <td>dhokra metal craft anklet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097228</th>\n",
       "      <td>pramud silver kid anklet pair yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690836</th>\n",
       "      <td>taraash sterling silver combo anklet toe ring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099625</th>\n",
       "      <td>akshara silver gemstone anklet red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800672</th>\n",
       "      <td>anklet woman girl pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>whiskey glass piece clear ml mart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>luigi bormioli michelangelo f whisky glass set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>single barrel whiskey glass set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>crystal glass twist design whiskey glass set m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>attractive personalized whiskey glass wedding ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90292 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title_proc\n",
       "1715584                          dhokra metal craft anklet\n",
       "1097228                   pramud silver kid anklet pair yr\n",
       "1690836  taraash sterling silver combo anklet toe ring ...\n",
       "1099625                 akshara silver gemstone anklet red\n",
       "800672                              anklet woman girl pack\n",
       "...                                                    ...\n",
       "4495                     whiskey glass piece clear ml mart\n",
       "4496        luigi bormioli michelangelo f whisky glass set\n",
       "4497                       single barrel whiskey glass set\n",
       "4498     crystal glass twist design whiskey glass set m...\n",
       "4499     attractive personalized whiskey glass wedding ...\n",
       "\n",
       "[90292 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['title_proc'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m parallel_proc(df_train[\u001b[39m'\u001b[39;49m\u001b[39mtitle_proc\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mto_frame(), preproc)\n",
      "Cell \u001b[1;32mIn [17], line 10\u001b[0m, in \u001b[0;36mparallel_proc\u001b[1;34m(df, fn, n_cores)\u001b[0m\n\u001b[0;32m      8\u001b[0m pool\u001b[39m.\u001b[39mclose()\n\u001b[0;32m      9\u001b[0m pool\u001b[39m.\u001b[39mjoin()\n\u001b[1;32m---> 10\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mconcat(res)\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[0;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    155\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m    156\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[39m    along the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[39m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    348\u001b[0m         objs,\n\u001b[0;32m    349\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    350\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m    351\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[0;32m    352\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m    353\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[0;32m    354\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    355\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m    356\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    357\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    358\u001b[0m     )\n\u001b[0;32m    360\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:437\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    433\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    434\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot concatenate object of type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(obj)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39monly Series and DataFrame objs are valid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         )\n\u001b[1;32m--> 437\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    439\u001b[0m     ndims\u001b[39m.\u001b[39madd(obj\u001b[39m.\u001b[39mndim)\n\u001b[0;32m    441\u001b[0m \u001b[39m# get the sample\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[39m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[39m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "parallel_proc(df_train['title_proc'], preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating X (independent variables) and y (dependent variable) matrices\n",
    "\n",
    "X = df_train[['title_proc','subcat_proc','desc_proc', 'pl_proc']]\n",
    "\n",
    "# X = df_train[['title_proc',','desc_proc', 'pl_proc']]\n",
    "\n",
    "y = df_train['category5_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train/Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8, test_size=0.2, stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Term-Frequency and Inverse document Frequency vectorizer with bigrams\n",
    "\n",
    "title_vec_model = TfidfVectorizer(max_df=0.3, min_df=0.0001, ngram_range = (1,1), stop_words = [\"english\"])\n",
    "desc_vec_model = TfidfVectorizer(max_df=0.3, min_df=0.0001, ngram_range = (1,1), stop_words = [\"english\"])\n",
    "subcat_vec_model = TfidfVectorizer(max_df=0.3, min_df=0.0001, ngram_range = (1,1), stop_words = [\"english\"])\n",
    "pl_vec_model = TfidfVectorizer(max_df=0.3, min_df=0.0001, ngram_range = (1,1), stop_words = [\"english\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fitting the Vectorisers on dependent variables\n",
    "\n",
    "title_mat_train = title_vec_model.fit_transform(X_train['title_proc'].fillna(''))\n",
    "desc_mat_train = desc_vec_model.fit_transform(X_train['desc_proc'].fillna(''))\n",
    "subcat_mat_train = subcat_vec_model.fit_transform(X_train['subcat_proc'].fillna(''))\n",
    "pl_mat_train = pl_vec_model.fit_transform(X_train['pl_proc'].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<72233x25131 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4269542 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mat_train = hstack((title_mat_train, desc_mat_train, subcat_mat_train, pl_mat_train))\n",
    "# X_mat_train = hstack((title_mat_train, desc_mat_train, pl_mat_train))\n",
    "\n",
    "X_mat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mat_test = title_vec_model.transform(X_test['title_proc'].fillna(''))\n",
    "desc_mat_test = desc_vec_model.transform(X_test['desc_proc'].fillna(''))\n",
    "subcat_mat_test = subcat_vec_model.transform(X_test['subcat_proc'].fillna(''))\n",
    "pl_mat_test = pl_vec_model.transform(X_test['pl_proc'].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18059x25131 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1055566 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mat_test = hstack((title_mat_test, desc_mat_test, subcat_mat_test, pl_mat_test))\n",
    "# X_mat_test = hstack((title_mat_test, desc_mat_test, pl_mat_test))\n",
    "\n",
    "X_mat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m lr_model \u001b[39m=\u001b[39m LogisticRegression(n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m lr_model\u001b[39m.\u001b[39;49mfit(X_mat_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1589\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1587\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1588\u001b[0m     prefer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprocesses\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1589\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m   1590\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m   1591\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1592\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49mprefer),\n\u001b[0;32m   1593\u001b[0m )(\n\u001b[0;32m   1594\u001b[0m     path_func(\n\u001b[0;32m   1595\u001b[0m         X,\n\u001b[0;32m   1596\u001b[0m         y,\n\u001b[0;32m   1597\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[0;32m   1598\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[0;32m   1599\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   1600\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m   1601\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m   1602\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1603\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[0;32m   1604\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[0;32m   1605\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1606\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m   1607\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1608\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m   1609\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[0;32m   1610\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[0;32m   1611\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[0;32m   1612\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1613\u001b[0m     )\n\u001b[0;32m   1614\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[0;32m   1615\u001b[0m )\n\u001b[0;32m   1617\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Vijay\\anaconda3\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "lr_model.fit(X_mat_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = lr_model.predict(X_mat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score Is :  0.9576942244864056\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score Is : \", accuracy_score(y_test, yhat))\n",
    "# print(\"ROC_Score : \" +str(roc_auc_score(y_test, yhat,multi_class=\"ovr\")))\n",
    "# print('classification Score =','\\n', classification_report(y_test,yhat))\n",
    "# print(\"Confusion Matrix HeatMap : \\n\", confusion_matrix(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Building the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train,X_test])\n",
    "y = pd.concat([y_train,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_proc</th>\n",
       "      <th>subcat_proc</th>\n",
       "      <th>desc_proc</th>\n",
       "      <th>pl_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40927</th>\n",
       "      <td>rodium plated cufflink men sj</td>\n",
       "      <td>cufflink</td>\n",
       "      <td>powerdressed work everyday premium workwear ac...</td>\n",
       "      <td>rodium plated cufflink men sj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73716</th>\n",
       "      <td>skore chocolate flavoured condom raised dot x</td>\n",
       "      <td>health beauty health care condom</td>\n",
       "      <td></td>\n",
       "      <td>skore chocolate flavoured condom raised dot x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23194</th>\n",
       "      <td>party pack drink</td>\n",
       "      <td>none</td>\n",
       "      <td>party pack drink contains sachet flavour unlea...</td>\n",
       "      <td>party pack drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850</th>\n",
       "      <td>crochet craving laptop sleeve</td>\n",
       "      <td>none</td>\n",
       "      <td>popitout brings decent classy range laptop mes...</td>\n",
       "      <td>crochet craving laptop sleeve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>jumbo golden raisin organic healthy naturally ...</td>\n",
       "      <td>none</td>\n",
       "      <td>jumbo golden raisin world huge almost big grap...</td>\n",
       "      <td>raisin gm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12311</th>\n",
       "      <td>lip hydration balm pack</td>\n",
       "      <td>none</td>\n",
       "      <td>type lip quantity ml country origin india</td>\n",
       "      <td>lip hydration balm pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14383</th>\n",
       "      <td>black net emboridered kurta set</td>\n",
       "      <td>salwar kameez</td>\n",
       "      <td>buy magnificent black net embroidered kurta se...</td>\n",
       "      <td>magnificent black net thread work kurta set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24522</th>\n",
       "      <td>customized name plate victorian pink flower</td>\n",
       "      <td>nameplate</td>\n",
       "      <td>style painting style watercolour paper victori...</td>\n",
       "      <td>victorian pink nameplate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>cold coffee bundle</td>\n",
       "      <td>drinkware</td>\n",
       "      <td>featured experience make summer cold coffee bu...</td>\n",
       "      <td>cold coffee bundle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>msm jadau kundan necklace set</td>\n",
       "      <td>necklace set</td>\n",
       "      <td>detail stone setting jadaumaterial base metalf...</td>\n",
       "      <td>msm jadau kundan necklace set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90292 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title_proc  \\\n",
       "40927                      rodium plated cufflink men sj   \n",
       "73716      skore chocolate flavoured condom raised dot x   \n",
       "23194                                   party pack drink   \n",
       "11850                      crochet craving laptop sleeve   \n",
       "6447   jumbo golden raisin organic healthy naturally ...   \n",
       "...                                                  ...   \n",
       "12311                            lip hydration balm pack   \n",
       "14383                    black net emboridered kurta set   \n",
       "24522        customized name plate victorian pink flower   \n",
       "2924                                  cold coffee bundle   \n",
       "2750                       msm jadau kundan necklace set   \n",
       "\n",
       "                            subcat_proc  \\\n",
       "40927                          cufflink   \n",
       "73716  health beauty health care condom   \n",
       "23194                              none   \n",
       "11850                              none   \n",
       "6447                               none   \n",
       "...                                 ...   \n",
       "12311                              none   \n",
       "14383                     salwar kameez   \n",
       "24522                         nameplate   \n",
       "2924                          drinkware   \n",
       "2750                       necklace set   \n",
       "\n",
       "                                               desc_proc  \\\n",
       "40927  powerdressed work everyday premium workwear ac...   \n",
       "73716                                                      \n",
       "23194  party pack drink contains sachet flavour unlea...   \n",
       "11850  popitout brings decent classy range laptop mes...   \n",
       "6447   jumbo golden raisin world huge almost big grap...   \n",
       "...                                                  ...   \n",
       "12311          type lip quantity ml country origin india   \n",
       "14383  buy magnificent black net embroidered kurta se...   \n",
       "24522  style painting style watercolour paper victori...   \n",
       "2924   featured experience make summer cold coffee bu...   \n",
       "2750   detail stone setting jadaumaterial base metalf...   \n",
       "\n",
       "                                             pl_proc  \n",
       "40927                  rodium plated cufflink men sj  \n",
       "73716  skore chocolate flavoured condom raised dot x  \n",
       "23194                               party pack drink  \n",
       "11850                  crochet craving laptop sleeve  \n",
       "6447                                       raisin gm  \n",
       "...                                              ...  \n",
       "12311                        lip hydration balm pack  \n",
       "14383    magnificent black net thread work kurta set  \n",
       "24522                       victorian pink nameplate  \n",
       "2924                              cold coffee bundle  \n",
       "2750                   msm jadau kundan necklace set  \n",
       "\n",
       "[90292 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vec_model_final = TfidfVectorizer(max_df=0.3, min_df=0.0001)\n",
    "desc_vec_model_final = TfidfVectorizer(max_df=0.3, min_df=0.0001)\n",
    "subcat_vec_model_final = TfidfVectorizer(max_df=0.3, min_df=0.0001)\n",
    "pl_vec_model_final = TfidfVectorizer(max_df=0.3, min_df=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mat = title_vec_model_final.fit_transform(X['title_proc'].fillna(''))\n",
    "desc_mat = desc_vec_model_final.fit_transform(X['desc_proc'].fillna(''))\n",
    "subcat_mat = subcat_vec_model_final.fit_transform(X['subcat_proc'].fillna(''))\n",
    "pl_mat = pl_vec_model_final.fit_transform(X['pl_proc'].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mat = hstack((title_mat, desc_mat, subcat_mat, pl_mat))\n",
    "# X_mat = hstack((title_mat, desc_mat, pl_mat))\n",
    "X_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_final = LogisticRegression(verbose=1, max_iter=75)\n",
    "lr_model_final.fit(X_mat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = lr_model_final.predict(X_mat)\n",
    "print(\"Accuracy Score Is : \", accuracy_score(y, yhat))\n",
    "# print(\"ROC_Score : \" +str(roc_auc_score(y, lr_model_final.predict(X_mat))))\n",
    "# al.predict_proba(X_mat),multi_class=\"ovr\")))\n",
    "# print('classification Score =','\\n', classification_report(y,yhat))\n",
    "# print(\"Confusion Matrix HeatMap : \\n\", confusion_matrix(y, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exporting the model\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(title_vec_model_final,'vectoriser_models/title_tfidf_cat5_v4.pkl')\n",
    "joblib.dump(desc_vec_model_final,'vectoriser_models/desc_tfidf_cat5_v4.pkl')\n",
    "joblib.dump(subcat_vec_model_final,'vectoriser_models/subcat_tfidf_cat5_v4.pkl')\n",
    "joblib.dump(pl_vec_model_final,'vectoriser_models/pl_tfidf_cat5_v4.pkl')\n",
    "\n",
    "joblib.dump(lr_model_final,'classification_models/logistic_regression_model_cat5_v4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing on baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_df = pd.read_csv(\"df_baseline_trainingset.csv\").rename(columns={'id':'_id', 'store_id':'_store_id', 'handle':'page_link', 'body_html':'description', 'product_type' :'shopify_subcategory'})\n",
    "prod_df = pd.read_csv(\"baseline_checks - Sheet2.csv\").rename(columns={'id':'_id', 'store_id':'_store_id', 'handle':'page_link', 'body_html':'description', 'product_type' :'shopify_subcategory'})\n",
    "\n",
    "prod_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_df['title_proc'] = prod_df['title'].apply(lambda x: preproc(x))\n",
    "prod_df['desc_proc'] = prod_df['description'].apply(lambda x: preproc(x))\n",
    "prod_df['subcat_proc'] = prod_df['shopify_subcategory'].apply(lambda x: preproc(x))\n",
    "prod_df['pl_proc'] = prod_df['page_link'].str.split('/products/',expand=True)[1].apply(lambda x: preproc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_rt = prod_df[['title_proc','subcat_proc','desc_proc', 'pl_proc']]\n",
    "# X_df_rt = prod_df[['title_proc','desc_proc', 'pl_proc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mat_df_rt = title_vec_model_final.transform(X_df_rt['title_proc'].fillna(''))\n",
    "desc_mat_df_rt = desc_vec_model_final.transform(X_df_rt['desc_proc'].fillna(''))\n",
    "pl_mat_df_rt= pl_vec_model_final.transform(X_df_rt['pl_proc'].fillna(''))\n",
    "subcat_mat_df_rt= subcat_vec_model_final.transform(X_df_rt['subcat_proc'].fillna(''))\n",
    "\n",
    "X_mat_prod_df = hstack((title_mat_df_rt, desc_mat_df_rt, subcat_mat_df_rt, pl_mat_df_rt))\n",
    "# X_mat_prod_df = hstack((title_mat_df_rt, desc_mat_df_rt, pl_mat_df_rt))\n",
    "\n",
    "X_mat_prod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Score Is : \", accuracy_score(prod_df['cat5_tokens'], lr_model_final.predict(X_mat_prod_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_df['cat5_predict'] = lr_model_final.predict(X_mat_prod_df)\n",
    "# prod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_df['check'] = prod_df['cat5_tokens'] == prod_df['cat5_predict']\n",
    "# prod_df['cat5_tokens'] == prod_df['cat5_predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_df[prod_df.check == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_df[prod_df.check == False].to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_df[prod_df.check == True].to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading prev cat5 Models\n",
    "\n",
    "latest_title_vec_model = load('/Users/apoorvatiwari/Documents/Apps_RecSy/downtown-product-classifcation/cat_level3/Old_Files/models_Backup/08112022/vectoriser_models/title_tfidf_cat5_gd_ct_5.pkl')\n",
    "latest_desc_vec_model = load('/Users/apoorvatiwari/Documents/Apps_RecSy/downtown-product-classifcation/cat_level3/Old_Files/models_Backup/08112022/vectoriser_models/desc_tfidf_cat5_gd_ct_5.pkl')\n",
    "latest_pl_vec_model = load('/Users/apoorvatiwari/Documents/Apps_RecSy/downtown-product-classifcation/cat_level3/Old_Files/models_Backup/08112022/vectoriser_models/pl_tfidf_cat5_gd_ct_5.pkl')\n",
    "# latest_subcat_vec_model = load('vectoriser_models/subcat_tfidf_cat5_gd_ct.pkl')\n",
    "latest_lr_model = load('/Users/apoorvatiwari/Documents/Apps_RecSy/downtown-product-classifcation/cat_level3/Old_Files/models_Backup/08112022/classification_models/logistic_regression_model_cat5_gd_ct_5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mat_df_rt = latest_title_vec_model.transform(X_df_rt['title_proc'].fillna(''))\n",
    "desc_mat_df_rt = latest_desc_vec_model.transform(X_df_rt['desc_proc'].fillna(''))\n",
    "pl_mat_df_rt= latest_pl_vec_model.transform(X_df_rt['pl_proc'].fillna(''))\n",
    "# subcat_mat_df_rt= latest_subcat_vec_model.transform(X_df_rt['subcat_proc'].fillna(''))\n",
    "\n",
    "# X_mat_prod_df = hstack((title_mat_df_rt, desc_mat_df_rt, subcat_mat_df_rt, pl_mat_df_rt))\n",
    "X_mat_prod_df = hstack((title_mat_df_rt, desc_mat_df_rt,  pl_mat_df_rt))\n",
    "\n",
    "X_mat_prod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Score Is : \", accuracy_score(prod_df['cat5_tokens'], latest_lr_model.predict(X_mat_prod_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.945321992709599 - 0.9198055893074119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8f46350a8bd583910db51a1d64064108b958bcbad0d091bd79d552637a4ab30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
